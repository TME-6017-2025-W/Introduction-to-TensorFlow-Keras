{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3i3xTnFCPQrzxUWz74pVP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UNB-TME-6017/intro-to-deep-learning-wk-5/blob/main/CNN_Introduction_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4D9Uyi-BjH5"
      },
      "outputs": [],
      "source": [
        "# create a simple convolutional neural network using tensorflow and keras\n",
        "# import the necessary packages\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# create a python function to get the mnist dataset\n",
        "def get_mnist_dataset():\n",
        "  # get the mnist dataset\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  # reshape the dataset\n",
        "  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "  # convert the dataset to float32\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  # normalize the dataset\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "  # return the dataset\n",
        "  return x_train, y_train, x_test, y_test\n",
        "\n",
        "# create a python function to get the model\n",
        "def get_model():\n",
        "  # create a sequential model\n",
        "  model = Sequential()\n",
        "  # add a convolutional layer\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "  # add a max pooling layer\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # add a dropout layer\n",
        "  model.add(Dropout(0.25))\n",
        "  # add a flatten layer\n",
        "  model.add(Flatten())\n",
        "  # add a dense layer\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  # add a dropout layer\n",
        "  model.add(Dropout(0.5))\n",
        "  # add a dense layer\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  # return the model\n",
        "  return model\n",
        "\n",
        "# create a python function to compile the model\n",
        "def compile_model(model):\n",
        "  # compile the model\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "  # return the model\n",
        "  return model\n",
        "\n",
        "# create a python function to train the model\n",
        "def train_model(model, x_train, y_train, batch_size, epochs):\n",
        "  # train the model\n",
        "  model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1)\n",
        "  # return the model\n",
        "  return model\n",
        "\n",
        "# create a python function to evaluate the model\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "  # evaluate the model\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  # print the score\n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "\n",
        "\n",
        "# create a python function to feedforward the model on new data\n",
        "def feedforward_model(model, x_test):\n",
        "  # feedforward the model on new data\n",
        "  predictions = model.predict(x_test)\n",
        "  # return the predictions\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the mnist dataset\n",
        "x_train, y_train, x_test, y_test = get_mnist_dataset()\n",
        "# convert y_train and y_test to categorical one-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)\n",
        "# get the model\n",
        "model = get_model()\n",
        "# compile the model\n",
        "model = compile_model(model)"
      ],
      "metadata": {
        "id": "18rGCPJ2By0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "oZDA7Z_dDG8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "model = train_model(model, x_train, y_train, batch_size=128, epochs=1)"
      ],
      "metadata": {
        "id": "4yR6bl7VBz0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "evaluate_model(model, x_test, y_test)"
      ],
      "metadata": {
        "id": "gvt43g75DhFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feedforward the model on new data\n",
        "predictions = feedforward_model(model, x_test)"
      ],
      "metadata": {
        "id": "RTZU2WhdDvL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "id": "I0-feTqkD-EX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = predictions.argmax(axis=1)\n",
        "predictions"
      ],
      "metadata": {
        "id": "qIBwYr_MEAiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6YxdwgeaEKcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "thE4alHQEWQD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}